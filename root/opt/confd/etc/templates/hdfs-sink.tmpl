# Basics #######################################################################

name={{ getenv "SERVICE_NAME" "hdfs" }}
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max={{ getenv "TASKS" "1" }}
topics={{ getenv "TOPICS" "test" }}

# HDFS #########################################################################

hdfs.url={{ getenv "HDFS_SERVICE" "hdfs://nameservice1" }}
hadoop.conf.dir=/opt/docker/conf/hadoop-conf
{{- if getenv "HADOOP_HOME" }}hadoop.home={{ getenv "HADOOP_HOME" }}{{- end}}
logs.dir={{ getenv "HDFS_LOGS_PATH" "/logs" }}

# Security #####################################################################

hdfs.authentication.kerberos={{ getenv "KERBEROS_AUTH" "false" }}
connect.hdfs.principal={{ getenv "KERBEROS_PRINCIPAL" "principal@EXAMPLE.COM" }}
connect.hdfs.keytab={{ getenv "KERBEROS_KEYTAB" "/opt/docker/auth/principal.keytab" }}
hdfs.namenode.principal={{ getenv "KERBEROS_HDFS_PRINCIPAL" "hdfs/nameservice1@EXAMPLE.COM" }}
kerberos.ticket.renew.period.ms={{ getenv "KERBEROS_TICKET_RENEW" "3600000" }}

# Connector ####################################################################

format.class=io.confluent.connect.hdfs.avro.AvroFormat
flush.size={{ getenv "FLUSH_SIZE" "10000" }}
rotate.interval.ms={{ getenv "ROTATE_INTERVAL" "-1" }}
rotate.schedule.interval.ms={{ getenv "ROTATE_SCHEDULE_INTERVAL" "600000" }}
schema.cache.size={{ getenv "SCHEMA_CACHE" "1000" }}
retry.backoff.ms={{ getenv "RETRY_BACKOFF" "10000" }}
shutdown.timeout.ms={{ getenv "SHUTDOWN_TIMEOUT" "3000" }}
filename.offset.zero.pad.width={{ getenv "FILENAME_ZERO_PAD" "10" }}

# Storage ######################################################################

storage.class=io.confluent.connect.hdfs.storage.HdfsStorage
topics.dir={{ getenv "HDFS_PATH" "/data" }}
{{- if getenv "STORE_URL" }}store.url={{ getenv "STORE_URL" }}{{- end}}
directory.delim={{ getenv "DIRECTORY_DELIM" "/" }}
file.delim={{ getenv "FILE_DELIM" "+" }}

# Partitioner ##################################################################

partitioner.class={{ getenv "PARTITIONER" "io.confluent.connect.hdfs.partitioner.TimeBasedPartitioner" }}
partition.field.name={{ getenv "PARTITION_FIELD" "id" }}
partition.duration.ms={{ getenv "PARTITION_DURATION" "600000" }}
path.format={{ getenv "PARTITION_FORMAT" "YYYY/MM/dd/HH/" }}
locale={{ getenv "LOCALE" "en" }}
timezone={{ getenv "TIMEZONE" "UTC" }}

# Hive #########################################################################

hive.integration={{ getenv "HIVE_INTEGRATION" "false" }}
{{- with $hiveIntegration := getenv "HIVE_INTEGRATION"}}
{{- if eq "true" $hiveIntegration }}
hive.metastore.uris={{ getenv "HIVE_METASTORE_URIS" }}
hive.conf.dir={{ getenv "HIVE_CONF_DIR" }}
hive.home={{ getenv "HIVE_HOME" }}
hive.database={{ getenv "HIVE_DATABASE" }}
{{- end}}
{{- end}}

# Schema #######################################################################

schema.compatibility={{ getenv "SCHEMA_COMPAT" "BACKWARD" }}
